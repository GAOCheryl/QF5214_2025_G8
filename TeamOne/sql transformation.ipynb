{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform Index Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN with 0\n",
    "import pandas as pd\n",
    "\n",
    "csv_file_path = 'D:/01 NUS/QF5214 Data Engineering/TeamOne/index_data.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_15280\\2774559220.py:46: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')  # Convert to datetime, setting invalid values as NaT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written into datacollection.index_data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "from io import StringIO\n",
    "\n",
    "# Database connection parameters\n",
    "database = \"QF5214\"\n",
    "username = \"postgres\"\n",
    "password = \"qf5214\"\n",
    "host = \"134.122.167.14\"\n",
    "port = 5555\n",
    "\n",
    "# CSV file path\n",
    "csv_file_path = 'D:/01 NUS/QF5214 Data Engineering/TeamOne/index_data.csv'\n",
    "\n",
    "# Extract schema and table name from CSV file name\n",
    "schema_name = \"datacollection\"\n",
    "table_name = os.path.splitext(os.path.basename(csv_file_path))[0]\n",
    "\n",
    "# Read CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Define columns that should be stored as numerical types\n",
    "numeric_columns = {\n",
    "    \"Open\": \"DOUBLE PRECISION\",\n",
    "    \"High\": \"DOUBLE PRECISION\",\n",
    "    \"Low\": \"DOUBLE PRECISION\",\n",
    "    \"Close\": \"DOUBLE PRECISION\",\n",
    "    \"Adj_Close\": \"DOUBLE PRECISION\",\n",
    "    \"Volume\": \"DOUBLE PRECISION\",\n",
    "}\n",
    "\n",
    "# Define columns that should be stored as datetime\n",
    "datetime_columns = {\n",
    "    \"Date\": \"DATE\" \n",
    "}\n",
    "\n",
    "# Convert necessary columns to appropriate types in pandas\n",
    "for col in numeric_columns.keys():\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')  # Convert to numeric, setting invalid values as NaN\n",
    "\n",
    "for col in datetime_columns.keys():\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')  # Convert to datetime, setting invalid values as NaT\n",
    "\n",
    "# Connect to the PostgreSQL database\n",
    "conn = psycopg2.connect(\n",
    "    dbname=database, \n",
    "    user=username, \n",
    "    password=password, \n",
    "    host=host, \n",
    "    port=port\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Ensure the schema exists\n",
    "cursor.execute(sql.SQL(\"SET search_path TO {};\").format(sql.Identifier(schema_name)))\n",
    "\n",
    "# Check if the table exists\n",
    "cursor.execute(sql.SQL(\"\"\"\n",
    "    SELECT EXISTS (\n",
    "        SELECT FROM information_schema.tables \n",
    "        WHERE table_schema = %s AND table_name = %s\n",
    "    );\n",
    "\"\"\"), (schema_name, table_name))\n",
    "\n",
    "table_exists = cursor.fetchone()[0]\n",
    "\n",
    "if not table_exists:\n",
    "    # Create the table dynamically with appropriate data types\n",
    "    column_definitions = []\n",
    "    for col in df.columns:\n",
    "        if col in numeric_columns:\n",
    "            col_type = numeric_columns[col]  # Assign predefined numeric type\n",
    "        elif col in datetime_columns:\n",
    "            col_type = datetime_columns[col]  # Assign datetime type\n",
    "        else:\n",
    "            col_type = \"TEXT\"  # Default type is TEXT for non-numeric columns\n",
    "        column_definitions.append(sql.SQL(\"{} {}\").format(sql.Identifier(col), sql.SQL(col_type)))\n",
    "\n",
    "    create_table_query = sql.SQL(\"CREATE TABLE {}.{} ({});\").format(\n",
    "        sql.Identifier(schema_name),\n",
    "        sql.Identifier(table_name),\n",
    "        sql.SQL(', ').join(column_definitions)\n",
    "    )\n",
    "    cursor.execute(create_table_query)\n",
    "\n",
    "# Use COPY to insert data in bulk\n",
    "csv_buffer = StringIO()\n",
    "df.to_csv(csv_buffer, index=False, header=False, date_format='%Y-%m-%d %H:%M:%S')  # 确保日期格式正确\n",
    "csv_buffer.seek(0)\n",
    "\n",
    "# Use COPY to insert the data from the StringIO buffer\n",
    "cursor.copy_expert(\n",
    "    sql.SQL(\"COPY {}.{} FROM STDIN WITH CSV NULL 'NaN'\").format(\n",
    "        sql.Identifier(schema_name),\n",
    "        sql.Identifier(table_name)\n",
    "    ),\n",
    "    csv_buffer\n",
    ")\n",
    "\n",
    "# Commit changes and close the connection\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(f\"Data successfully written into {schema_name}.{table_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN with 0\n",
    "import pandas as pd\n",
    "\n",
    "csv_file_path = 'D:/01 NUS/QF5214 Data Engineering/TeamOne/stock_data.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_15280\\3014174843.py:53: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')  # Convert to datetime, setting invalid values as NaT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written into datacollection.stock_data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "from io import StringIO\n",
    "\n",
    "# Database connection parameters\n",
    "database = \"QF5214\"\n",
    "username = \"postgres\"\n",
    "password = \"qf5214\"\n",
    "host = \"134.122.167.14\"\n",
    "port = 5555\n",
    "\n",
    "# CSV file path\n",
    "csv_file_path = 'D:/01 NUS/QF5214 Data Engineering/TeamOne/stock_data.csv'\n",
    "\n",
    "# Extract schema and table name from CSV file name\n",
    "schema_name = \"datacollection\"\n",
    "table_name = os.path.splitext(os.path.basename(csv_file_path))[0]\n",
    "\n",
    "# Read CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Define columns that should be stored as numerical types\n",
    "numeric_columns = {\n",
    "    \"Open\": \"DOUBLE PRECISION\",\n",
    "    \"High\": \"DOUBLE PRECISION\",\n",
    "    \"Low\": \"DOUBLE PRECISION\",\n",
    "    \"Close\": \"DOUBLE PRECISION\",\n",
    "    \"Adj_Close\": \"DOUBLE PRECISION\",\n",
    "    \"Volume\": \"DOUBLE PRECISION\",\n",
    "    \"PE\": \"DOUBLE PRECISION\",\n",
    "    \"PB\": \"DOUBLE PRECISION\",\n",
    "    \"PS\": \"DOUBLE PRECISION\",\n",
    "    \"ROE\": \"DOUBLE PRECISION\",\n",
    "    \"PM\": \"DOUBLE PRECISION\",\n",
    "    \"IN\": \"DOUBLE PRECISION\",\n",
    "    \"Market_Cap\": \"DOUBLE PRECISION\"\n",
    "}\n",
    "\n",
    "# Define columns that should be stored as datetime\n",
    "datetime_columns = {\n",
    "    \"Date\": \"DATE\" \n",
    "}\n",
    "\n",
    "# Convert necessary columns to appropriate types in pandas\n",
    "for col in numeric_columns.keys():\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')  # Convert to numeric, setting invalid values as NaN\n",
    "\n",
    "for col in datetime_columns.keys():\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')  # Convert to datetime, setting invalid values as NaT\n",
    "\n",
    "# Connect to the PostgreSQL database\n",
    "conn = psycopg2.connect(\n",
    "    dbname=database, \n",
    "    user=username, \n",
    "    password=password, \n",
    "    host=host, \n",
    "    port=port\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Ensure the schema exists\n",
    "cursor.execute(sql.SQL(\"SET search_path TO {};\").format(sql.Identifier(schema_name)))\n",
    "\n",
    "# Check if the table exists\n",
    "cursor.execute(sql.SQL(\"\"\"\n",
    "    SELECT EXISTS (\n",
    "        SELECT FROM information_schema.tables \n",
    "        WHERE table_schema = %s AND table_name = %s\n",
    "    );\n",
    "\"\"\"), (schema_name, table_name))\n",
    "\n",
    "table_exists = cursor.fetchone()[0]\n",
    "\n",
    "if not table_exists:\n",
    "    # Create the table dynamically with appropriate data types\n",
    "    column_definitions = []\n",
    "    for col in df.columns:\n",
    "        if col in numeric_columns:\n",
    "            col_type = numeric_columns[col]  # Assign predefined numeric type\n",
    "        elif col in datetime_columns:\n",
    "            col_type = datetime_columns[col]  # Assign datetime type\n",
    "        else:\n",
    "            col_type = \"TEXT\"  # Default type is TEXT for non-numeric columns\n",
    "        column_definitions.append(sql.SQL(\"{} {}\").format(sql.Identifier(col), sql.SQL(col_type)))\n",
    "\n",
    "    create_table_query = sql.SQL(\"CREATE TABLE {}.{} ({});\").format(\n",
    "        sql.Identifier(schema_name),\n",
    "        sql.Identifier(table_name),\n",
    "        sql.SQL(', ').join(column_definitions)\n",
    "    )\n",
    "    cursor.execute(create_table_query)\n",
    "\n",
    "# Use COPY to insert data in bulk\n",
    "csv_buffer = StringIO()\n",
    "df.to_csv(csv_buffer, index=False, header=False, date_format='%Y-%m-%d %H:%M:%S')  # 确保日期格式正确\n",
    "csv_buffer.seek(0)\n",
    "\n",
    "# Use COPY to insert the data from the StringIO buffer\n",
    "cursor.copy_expert(\n",
    "    sql.SQL(\"COPY {}.{} FROM STDIN WITH CSV NULL 'NaN'\").format(\n",
    "        sql.Identifier(schema_name),\n",
    "        sql.Identifier(table_name)\n",
    "    ),\n",
    "    csv_buffer\n",
    ")\n",
    "\n",
    "# Commit changes and close the connection\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(f\"Data successfully written into {schema_name}.{table_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
